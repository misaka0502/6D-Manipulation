{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import meshcat\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from rdt.common import path_util, util\n",
    "from rdt.camera.simple_multicam import MultiRGBDCalibrated\n",
    "from rdt.common import mc_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7002/static/\n"
     ]
    }
   ],
   "source": [
    "mc_vis = meshcat.Visualizer(zmq_url='tcp://127.0.0.1:6001')\n",
    "mc_vis['scene'].delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path: /home/anthony/repos/research/robust-rearrangement/src/real/test_refactor\n",
      "Demo path: /home/anthony/repos/research/robust-rearrangement/src/real/test_refactor/2024-05-02T19:45:35.pkl\n",
      "File saved as test.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls src=\"test.mp4\" width=\"640\" height=\"480\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.visualization.render_mp4 import mp4_from_pickle_jupyter\n",
    "import os\n",
    "os.environ['IMAGEIO_FFMPEG_EXE'] = '/usr/bin/ffmpeg'\n",
    "\n",
    "base_path = Path(\"/home/anthony/repos/research/robust-rearrangement/src/real/test_refactor\")\n",
    "demo_path = base_path / \"2024-05-02T19:45:35.pkl\"\n",
    "print(f'Base path: {base_path}\\nDemo path: {demo_path}')\n",
    "\n",
    "mp4_from_pickle_jupyter(demo_path, 'test.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path: /home/anthony/repos/research/improbable_rdt/examples/teleop_demos/lamp_shade_pick_place_basic_rs2\n",
      "Demo path: /home/anthony/repos/research/improbable_rdt/examples/teleop_demos/lamp_shade_pick_place_basic_rs2/2024-05-01 17:44:36.703058/episode_data.pkl\n",
      "dict_keys(['robot_state', 'image_front', 'image_wrist', 'actions'])\n",
      "Key: robot_state, Length: 119, Type: <class 'dict'>\n",
      "Key: image_front, Length: 119, Type: <class 'dict'>\n",
      "Key: image_wrist, Length: 119, Type: <class 'dict'>\n",
      "Key: actions, Length: 119, Type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(\"/home/anthony/repos/research/improbable_rdt/examples/teleop_demos/lamp_shade_pick_place_basic_rs2\")\n",
    "demo_path = base_path / \"2025-05-01 17:44:36.703058\" / \"episode_data.pkl\"\n",
    "print(f'Base path: {base_path}\\nDemo path: {demo_path}')\n",
    "\n",
    "with open(demo_path, 'rb') as f:\n",
    "    demo_data = pickle.load(f)\n",
    "\n",
    "print(demo_data.keys())\n",
    "for k in demo_data.keys():\n",
    "    print(f'Key: {k}, Length: {len(demo_data[k])}, Type: {type(demo_data[k][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ee_pose', 'joint_positions', 'gripper_width'])\n",
      "dict_keys(['rgb', 'depth'])\n",
      "dict_keys(['rgb', 'depth'])\n"
     ]
    }
   ],
   "source": [
    "print(demo_data['robot_state'][0].keys())\n",
    "print(demo_data['image_front'][0].keys())\n",
    "print(demo_data['image_wrist'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing camera cam_0\n"
     ]
    }
   ],
   "source": [
    "depth_images = []\n",
    "point_clouds = []\n",
    "calib_fname = Path(path_util.get_rdt_src()) / \"robot/camera_calibration_files\" / \"test/cam_0_calib_base_to_cam.json\"\n",
    "cam = MultiRGBDCalibrated(cam_names=['cam_0'], calib_filenames=[calib_fname]).cams[0]\n",
    "# cam_intrinsics = np.array([\n",
    "#     [613.14752197,   0.        , 326.19647217],\n",
    "#     [  0.        , 613.16229248, 244.59855652],\n",
    "#     [  0.        ,   0.        ,   1.        ]]\n",
    "# )\n",
    "cam_intrinsics = np.array([\n",
    "       [385.75708008,   0.        , 326.95498657],\n",
    "       [  0.        , 385.36810303, 237.9675293 ],\n",
    "       [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "cam.cam_int_mat = cam_intrinsics\n",
    "cam._init_pers_mat()\n",
    "cam_pose_world = cam.cam_ext_mat\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    rgb = demo_data['image_front'][i]['rgb']\n",
    "    depth = demo_data['image_front'][i]['depth'] * 0.001\n",
    "    valid = depth < cam.depth_max\n",
    "    valid = np.logical_and(valid, depth > cam.depth_min)\n",
    "    depth_valid = copy.deepcopy(depth)\n",
    "    depth_valid[np.logical_not(valid)] = 0.0 # not exactly sure what to put for invalid depth\n",
    "\n",
    "    pcd_cam = cam.get_pcd(in_world=False, filter_depth=False, rgb_image=rgb, depth_image=depth_valid)[0]\n",
    "    pcd_cam_img = pcd_cam.reshape(depth.shape[0], depth.shape[1], 3)\n",
    "    pcd_world = util.transform_pcd(pcd_cam, cam_pose_world)\n",
    "    pcd_world_img = pcd_world.reshape(depth.shape[0], depth.shape[1], 3)\n",
    "    pcd_dict = {\n",
    "        'world': pcd_world,\n",
    "        'cam': pcd_cam_img,\n",
    "        'cam_img': pcd_cam,\n",
    "        'world_img': pcd_world_img,\n",
    "        'cam_pose_mat': cam_pose_world\n",
    "    }\n",
    "\n",
    "    depth_images.append(depth_valid)\n",
    "    point_clouds.append(pcd_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(demo_data['robot_state'])\n",
    "\n",
    "def state_to_ee_pose(rs):\n",
    "    ee_pose_arr = rs['ee_pose']\n",
    "    ee_pose_mat = np.eye(4)\n",
    "    ee_pose_mat[:-1, -1] = ee_pose_arr[:3]\n",
    "    ee_pose_mat[:-1, :-1] = R.from_quat(ee_pose_arr[3:7]).as_matrix()\n",
    "    return ee_pose_mat\n",
    "\n",
    "\n",
    "def action_to_des_ee_pose(act):\n",
    "    des_ee_pose_arr = act[:-1] # no gripper\n",
    "    des_ee_pose_mat = np.eye(4)\n",
    "    des_ee_pose_mat[:-1, -1] = des_ee_pose_arr[:3]\n",
    "    des_ee_pose_mat[:-1, :-1] = R.from_quat(des_ee_pose_arr[3:7]).as_matrix()\n",
    "    return des_ee_pose_mat\n",
    "\n",
    "idx = 0\n",
    "\n",
    "mc_vis['scene/sa'].delete()\n",
    "\n",
    "# plot the states\n",
    "for i in range(n):\n",
    "    ee_pose_mat = state_to_ee_pose(demo_data['robot_state'][i])\n",
    "    des_ee_pose_mat = action_to_des_ee_pose(demo_data['actions'][i])\n",
    "\n",
    "    mc_util.meshcat_frame_show(mc_vis, f'scene/sa/{idx}/{i}/state', ee_pose_mat)\n",
    "    mc_util.meshcat_frame_show(mc_vis, f'scene/sa/{idx}/{i}/action', des_ee_pose_mat)\n",
    "\n",
    "    idx = i // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_vis['scene/pcd'].delete()\n",
    "pcd_idx = 21\n",
    "mc_util.meshcat_pcd_show(mc_vis, point_clouds[pcd_idx], (0, 0, 0), name=f'scene/pcd/{pcd_idx}/point_cloud', size=0.002)\n",
    "\n",
    "# mc_vis['scene/sa'].delete()\n",
    "# for i in range(n):\n",
    "#     mc_util.meshcat_pcd_show(mc_vis, point_clouds[i], (0, 0, 0), name=f'scene/pcd/point_cloud', size=0.002)\n",
    "#     time.sleep(0.1)\n",
    "\n",
    "#     ee_pose_mat = state_to_ee_pose(demo_data['robot_state'][i])\n",
    "#     des_ee_pose_mat = action_to_des_ee_pose(demo_data['actions'][i])\n",
    "\n",
    "#     mc_util.meshcat_frame_show(mc_vis, f'scene/sa/state', ee_pose_mat)\n",
    "#     mc_util.meshcat_frame_show(mc_vis, f'scene/sa/action', des_ee_pose_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furniture-rdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
